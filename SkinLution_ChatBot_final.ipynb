{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da813ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "import getpass\n",
    "import os\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "import bs4\n",
    "from langchain.vectorstores import Chroma, FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader, PyPDFLoader\n",
    "from langchain_community.document_loaders import CSVLoader\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableBranch\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "275ec8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0aab2e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_api_keys():\n",
    "    os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "    os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "    os.environ[\"LANGCHAIN_API_KEY\"] = os.environ.get(\"LANGCHAIN_API_KEY\")\n",
    "\n",
    "# API 키 설정 호출\n",
    "set_api_keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e069348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 8/8 [00:38<00:00,  4.81s/it]\n",
      "100%|██████████████████████████████████████████████████████████████████████████████████| 24/24 [00:06<00:00,  3.64it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_documents(data_path: str):\n",
    "    documents = {}\n",
    "    \n",
    "    pdf_loader = DirectoryLoader(\".\", glob=f\"{data_path}/*.pdf\", show_progress=True)\n",
    "    documents['pdf_docs'] = pdf_loader.load()\n",
    "    \n",
    "    txt_loader = DirectoryLoader(\".\", glob=f\"{data_path}/*.txt\", show_progress=True)\n",
    "    documents['txt_docs'] = txt_loader.load()\n",
    "    \n",
    "    csv_loader = CSVLoader(file_path=f\"{data_path}/화장품데이터.csv\", encoding='utf-8')\n",
    "    documents['csv_docs'] = csv_loader.load()\n",
    "    return documents\n",
    "    \n",
    "def print_documents(documents):\n",
    "    print(f\"문서의 수: {len(documents)})\\n\")\n",
    "    for i in range(len(documents)):\n",
    "        print(documents[i].metadata)\n",
    "        \n",
    "data_path = \"SkinLution_data\"\n",
    "docs = load_documents(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d2da938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서의 수: 8)\n",
      "\n",
      "{'source': 'SkinLution_data\\\\The_Effect_of_P.pdf'}\n",
      "{'source': 'SkinLution_data\\\\고려엉겅퀴의_HPLC_패턴_.pdf'}\n",
      "{'source': 'SkinLution_data\\\\목단피_에탄올_추출물의_B1.pdf'}\n",
      "{'source': 'SkinLution_data\\\\세안화장품_사용에_따른_20.pdf'}\n",
      "{'source': 'SkinLution_data\\\\아토피_피부의_임상연구__J.pdf'}\n",
      "{'source': 'SkinLution_data\\\\울금의_항산화_및_미백효과.pdf'}\n",
      "{'source': 'SkinLution_data\\\\제주도_토착_우뭇가사리의_항.pdf'}\n",
      "{'source': 'SkinLution_data\\\\화장품에서_키토산_성분의_기.pdf'}\n"
     ]
    }
   ],
   "source": [
    "print_documents(docs['pdf_docs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f9fab63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF 문서 분할 후 총 청크 수: 458\n",
      "TXT 문서 분할 후 총 청크 수: 461\n"
     ]
    }
   ],
   "source": [
    "def split_documents(documents, chunk_size=500, chunk_overlap=100, add_start_index=True):\n",
    "    splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        add_start_index=add_start_index\n",
    "    )\n",
    "    return splitter.split_documents(documents)\n",
    "\n",
    "pdf_splits = split_documents(docs['pdf_docs'], chunk_size=500, chunk_overlap=100)\n",
    "print(f\"PDF 문서 분할 후 총 청크 수: {len(pdf_splits)}\")\n",
    "\n",
    "txt_splits = split_documents(docs['txt_docs'], chunk_size=300, chunk_overlap=50)\n",
    "print(f\"TXT 문서 분할 후 총 청크 수: {len(txt_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffeab344",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoban\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "def create_vectorstore(documents, embedding_model=None):\n",
    "    embedding_model = embedding_model or OpenAIEmbeddings()\n",
    "    vectorstore = FAISS.from_documents(documents=documents, embedding=embedding_model)\n",
    "    return vectorstore\n",
    "\n",
    "def merge_vectorstores(primary_store, secondary_store):\n",
    "    primary_store.merge_from(secondary_store)\n",
    "\n",
    "pdf_vectorstore = create_vectorstore(pdf_splits)\n",
    "txt_vectorstore = create_vectorstore(txt_splits)\n",
    "cosmetic_vectorstore = create_vectorstore(docs['csv_docs'])\n",
    "\n",
    "# PDF와 TXT 벡터 스토어 병합\n",
    "merge_vectorstores(pdf_vectorstore, txt_vectorstore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11285f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is the number of chunks to retrieve\n",
    "retriever1 = pdf_vectorstore.as_retriever(k=3)\n",
    "retriever2 = cosmetic_vectorstore.as_retriever(k=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a59b222a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 선택된 벡터스토어에 따라 검색 수행하는 함수\n",
    "def is_cosmetic_query(user_message):\n",
    "    # 간단한 키워드 기반 분류기 => 머신러닝 모델로 바꿀 수 있음(사용자의 질문이 화장품 추천을 바라는 것인지 아닌지로 레이블링)\n",
    "    cosmetic_keywords = [\"화장품\", \"제품\", \"스킨케어\", \"로션\", \"크림\"]\n",
    "    return any(keyword in user_message for keyword in cosmetic_keywords)\n",
    "                         \n",
    "# 적절한 vectorstore를 선택하는 로직\n",
    "def select_vectorstore(user_message):\n",
    "    if is_cosmetic_query(user_message):\n",
    "        return retriever2\n",
    "    else:\n",
    "        return retriever1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7de1d7a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hoban\\anaconda3\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 0.3.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "# GPT LLM 생성\n",
    "llm = ChatOpenAI(\n",
    "    temperature=0,  # 창의성 (0.0 ~ 2.0) 낮을수록 같은 질문에 같은 대답\n",
    "    model_name=\"gpt-4o-mini\",  # 모델명\n",
    "    #streaming=True,\n",
    "    #callbacks=[StreamingStdOutCallbackHandler()], #스트리밍으로 답변 받기\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21a4f299",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_retrieval(user_message):\n",
    "    selected_vectorstore = select_vectorstore(user_message)\n",
    "    # 질의 변환 및 검색 수행\n",
    "    query_transform_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "            (\n",
    "                \"user\",\n",
    "                \"Given the above conversation, generate a search query to look up in order to get information relevant to the conversation. Only respond with the query, nothing else.\",\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    question_answering_prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"Answer the user's question based on the below context:\\n\\n{context}\",\n",
    "            ),\n",
    "            MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    query_transforming_retriever_chain = RunnableBranch(\n",
    "        (\n",
    "            lambda x: len(x.get(\"messages\", [])) == 1,\n",
    "            (lambda x: x[\"messages\"][-1].content) | selected_vectorstore,\n",
    "        ),\n",
    "        query_transform_prompt \n",
    "        | llm \n",
    "        | StrOutputParser() \n",
    "        | selected_vectorstore,\n",
    "    ).with_config(run_name=\"chat_retriever_chain\")\n",
    "\n",
    "    document_chain = create_stuff_documents_chain(llm, question_answering_prompt)\n",
    "\n",
    "    conversational_retrieval_chain = RunnablePassthrough.assign(\n",
    "        context=query_transforming_retriever_chain,\n",
    "    ).assign(\n",
    "        answer=document_chain,\n",
    "    )\n",
    "    return conversational_retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5b9046b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "질문할 내용을 입력하세요: 지성 피부는 어떻게 관리해야해?\n",
      "지성 피부를 관리하기 위해서는 다음과 같은 방법을 고려할 수 있습니다:\n",
      "\n",
      "1. **세안**: 하루에 두 번, 아침과 저녁에 적절한 세안제를 사용하여 피부의 유분과 불순물을 깨끗이 제거합니다. 너무 강한 세안제는 오히려 피부를 자극할 수 있으니, 부드러운 제품을 선택하는 것이 좋습니다.\n",
      "\n",
      "2. **보습**: 지성 피부라고 해서 보습을 소홀히 해서는 안 됩니다. 가벼운 수분 크림이나 젤 타입의 보습제를 사용하여 수분을 공급해 주세요. 오일 프리 제품을 선택하는 것이 좋습니다.\n",
      "\n",
      "3. **각질 제거**: 주 1~2회 각질 제거를 통해 모공을 깨끗하게 유지하고, 피지 분비를 조절할 수 있습니다. 너무 자주 각질 제거를 하면 피부가 자극을 받을 수 있으니 주의해야 합니다.\n",
      "\n",
      "4. **선크림 사용**: 자외선 차단제를 꼭 사용하여 피부를 보호하세요. 지성 피부에 적합한 오일 프리 선크림을 선택하는 것이 좋습니다.\n",
      "\n",
      "5. **식습관**: 기름진 음식이나 당분이 많은 음식을 피하고, 신선한 과일과 채소를 많이 섭취하여 피부 건강을 개선할 수 있습니다.\n",
      "\n",
      "6. **스트레스 관리**: 스트레스는 피부 상태에 영향을 미칠 수 있으므로, 적절한 운동과 휴식을 통해 스트레스를 관리하는 것이 중요합니다.\n",
      "\n",
      "이 외에도 개인의 피부 상태에 따라 적절한 제품을 선택하고, 필요시 피부과 전문의와 상담하는 것이 좋습니다.\n",
      "답변에 활용한 정보: SkinLution_data\\모공 작아지려면 어떻게 해야하나요 [피부과전문의 피부심].txt\n",
      "==========================================================\n",
      "질문할 내용을 입력하세요: 그렇다면 보습에 좋은 수분 크림은 뭐야?\n",
      "보습에 좋은 수분 크림을 선택할 때는 다음과 같은 성분을 포함한 제품을 고려하는 것이 좋습니다:\n",
      "\n",
      "1. **히알루론산**: 수분을 끌어당기고 유지하는 데 도움을 주는 성분으로, 피부에 깊은 수분을 공급합니다.\n",
      "\n",
      "2. **글리세린**: 수분을 끌어당기는 성질이 있어 피부를 촉촉하게 유지하는 데 효과적입니다.\n",
      "\n",
      "3. **세라마이드**: 피부 장벽을 강화하고 수분 손실을 방지하는 데 도움을 줍니다.\n",
      "\n",
      "4. **알로에 베라**: 진정 효과가 있으며, 수분을 공급해 주는 성분입니다.\n",
      "\n",
      "5. **판테놀 (비타민 B5)**: 피부를 진정시키고 보습 효과를 높여주는 성분입니다.\n",
      "\n",
      "6. **식물성 오일**: 호호바 오일, 아르간 오일 등은 피부에 영양을 주고 수분을 잠가주는 역할을 합니다.\n",
      "\n",
      "추천할 만한 수분 크림 브랜드로는 다음과 같은 것들이 있습니다:\n",
      "\n",
      "- **라로슈포제 (La Roche-Posay)**: 수분 공급과 진정 효과가 뛰어난 제품이 많습니다.\n",
      "- **세타필 (Cetaphil)**: 민감한 피부에도 적합한 보습 제품을 제공합니다.\n",
      "- **네이처리퍼블릭 (Nature Republic)**: 자연 유래 성분을 사용한 수분 크림이 많습니다.\n",
      "- **더페이스샵 (The Face Shop)**: 다양한 수분 크림 라인이 있어 선택의 폭이 넓습니다.\n",
      "\n",
      "각 제품의 성분을 확인하고, 자신의 피부 타입에 맞는 제품을 선택하는 것이 중요합니다. 필요시 피부과 전문의와 상담하여 적합한 제품을 추천받는 것도 좋은 방법입니다.\n",
      "답변에 활용한 정보: SkinLution_data/화장품데이터.csv\n",
      "==========================================================\n",
      "질문할 내용을 입력하세요: -1\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def main():\n",
    "    demo_ephemeral_chat_history = ChatMessageHistory()\n",
    "    printed_messages = []\n",
    "    \n",
    "    while True:\n",
    "        user_message = input(\"질문할 내용을 입력하세요: \")\n",
    "        if user_message == \"-1\":\n",
    "            break\n",
    "        \n",
    "        demo_ephemeral_chat_history.add_user_message(user_message)\n",
    "        \n",
    "        # Perform retrieval based on user input\n",
    "        response = perform_retrieval(user_message).invoke({\"messages\": demo_ephemeral_chat_history.messages})\n",
    "        \n",
    "        # Add AI response to the chat history\n",
    "        demo_ephemeral_chat_history.add_ai_message(response[\"answer\"])\n",
    "        \n",
    "        # Extract the title and metadata from the first document in the context\n",
    "        first_document_title, first_document_metadata = extract_document_info(response)\n",
    "        \n",
    "        # Display new AI messages\n",
    "        display_ai_messages(demo_ephemeral_chat_history, printed_messages)\n",
    "        \n",
    "        # Display document metadata if applicable\n",
    "        if first_document_metadata:\n",
    "            display_document_metadata(first_document_metadata)\n",
    "        \n",
    "        print(\"==========================================================\")\n",
    "\n",
    "def extract_document_info(response):\n",
    "    if \"context\" in response and response[\"context\"]:\n",
    "        first_document = response[\"context\"][0]\n",
    "        title = first_document.page_content.split('\\n')[0].strip()\n",
    "        metadata = first_document.metadata\n",
    "        return title, metadata\n",
    "    return None, None\n",
    "\n",
    "def display_ai_messages(chat_history, printed_messages):\n",
    "    ai_messages = [msg.content for msg in chat_history.messages if isinstance(msg, AIMessage)]\n",
    "    for msg in ai_messages:\n",
    "        if msg not in printed_messages:\n",
    "            print(msg)\n",
    "            printed_messages.append(msg)\n",
    "\n",
    "def display_document_metadata(metadata):\n",
    "    for key, value in metadata.items():\n",
    "        if key == \"source\":\n",
    "            match = re.search(r'\\\\(.+?)\\s-\\s', value)\n",
    "            if match:\n",
    "                value = match.group(1)\n",
    "            print(\"답변에 활용한 정보:\", value)\n",
    "\n",
    "# 프로그램 시작\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f49daed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
      "     -------------------------------------- 255.8/255.8 kB 7.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: tqdm in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sentence-transformers) (0.23.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sentence-transformers) (2.3.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.9.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sentence-transformers) (4.41.1)\n",
      "Requirement already satisfied: Pillow in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sentence-transformers) (1.0.2)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.28.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.8.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.10.1)\n",
      "Requirement already satisfied: mkl<=2021.4.0,>=2021.1.1 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (2.11.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.19.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2022.7.9)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.23.5)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.3)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.1.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from scikit-learn->sentence-transformers) (2.2.0)\n",
      "Requirement already satisfied: intel-openmp==2021.* in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.4.0)\n",
      "Requirement already satisfied: tbb==2021.* in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers) (2021.12.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.1.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (1.26.18)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\hoban\\anaconda3\\lib\\site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.2.1)\n",
      "Installing collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1e7ee3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# CLIP 모델 불러오기\n",
    "clip_model = SentenceTransformer('clip-ViT-B-32')\n",
    "\n",
    "# 피부 상태 설명 리스트 (필요에 따라 확장 가능)\n",
    "skin_descriptions = [\n",
    "    \"얼굴이 붉은 피부\",\n",
    "    \"건조한 피부\",\n",
    "    \"유분기가 있는 피부\",\n",
    "    \"평범한 피부\",\n",
    "]\n",
    "\n",
    "# 각 피부 설명에 대한 텍스트 임베딩 생성\n",
    "skin_description_embeddings = [clip_model.encode(desc, convert_to_tensor=True) for desc in skin_descriptions]\n",
    "\n",
    "def analyze_skin_image(image_path):\n",
    "    # 이미지 열기 및 CLIP 임베딩 생성\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    image_embedding = clip_model.encode(image, convert_to_tensor=True)\n",
    "    \n",
    "    # 유사도 계산\n",
    "    similarities = [util.pytorch_cos_sim(image_embedding, desc_embedding).item()\n",
    "                    for desc_embedding in skin_description_embeddings]\n",
    "    \n",
    "    # 가장 높은 유사도 점수를 가진 피부 상태 설명 선택\n",
    "    max_similarity_index = similarities.index(max(similarities))\n",
    "    best_matching_description = skin_descriptions[max_similarity_index]\n",
    "    best_similarity_score = similarities[max_similarity_index]\n",
    "    \n",
    "    return best_matching_description, best_similarity_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "79458b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "해당 피부 상태로 가장 유사한 설명: 평범한 피부\n",
      "유사도 점수: 0.21\n",
      "해당 피부 상태로 가장 유사한 설명: 건조한 피부\n",
      "유사도 점수: 0.22\n",
      "해당 피부 상태로 가장 유사한 설명: 유분기가 있는 피부\n",
      "유사도 점수: 0.22\n",
      "해당 피부 상태로 가장 유사한 설명: 유분기가 있는 피부\n",
      "유사도 점수: 0.22\n",
      "해당 피부 상태로 가장 유사한 설명: 유분기가 있는 피부\n",
      "유사도 점수: 0.26\n"
     ]
    }
   ],
   "source": [
    "image_path = \"평범피부.jpg\"  # 사용자가 업로드한 이미지 파일 경로\n",
    "description, score = analyze_skin_image(image_path)\n",
    "\n",
    "print(f\"해당 피부 상태로 가장 유사한 설명: {description}\")\n",
    "print(f\"유사도 점수: {score:.2f}\")\n",
    "\n",
    "image_path = \"피부1.jpg\"  # 사용자가 업로드한 이미지 파일 경로\n",
    "description, score = analyze_skin_image(image_path)\n",
    "\n",
    "print(f\"해당 피부 상태로 가장 유사한 설명: {description}\")\n",
    "print(f\"유사도 점수: {score:.2f}\")\n",
    "\n",
    "image_path = \"피부2.jpg\"  # 사용자가 업로드한 이미지 파일 경로\n",
    "description, score = analyze_skin_image(image_path)\n",
    "\n",
    "print(f\"해당 피부 상태로 가장 유사한 설명: {description}\")\n",
    "print(f\"유사도 점수: {score:.2f}\")\n",
    "\n",
    "image_path = \"민감피부2.jpg\"  # 사용자가 업로드한 이미지 파일 경로\n",
    "description, score = analyze_skin_image(image_path)\n",
    "\n",
    "print(f\"해당 피부 상태로 가장 유사한 설명: {description}\")\n",
    "print(f\"유사도 점수: {score:.2f}\")\n",
    "\n",
    "image_path = \"내피부.jpg\"  # 사용자가 업로드한 이미지 파일 경로\n",
    "description, score = analyze_skin_image(image_path)\n",
    "\n",
    "print(f\"해당 피부 상태로 가장 유사한 설명: {description}\")\n",
    "print(f\"유사도 점수: {score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
